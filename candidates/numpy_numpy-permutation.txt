astropy_astropy-1.3.0: 0	
***************************************************	
scipy_scipy-0.19.0: 8	
===================================================================	
kmeans: 132	
----------------------------	

"\n    Performs k-means on a set of observation vectors forming k clusters.\n\n    The k-means algorithm adjusts the centroids until sufficient\n    progress cannot be made, i.e. the change in distortion since\n    the last iteration is less than some threshold. This yields\n    a code book mapping centroids to codes and vice versa.\n\n    Distortion is defined as the sum of the squared differences\n    between the observations and the corresponding centroid.\n\n    Parameters\n    ----------\n    obs : ndarray\n       Each row of the M by N array is an observation vector. The\n       columns are the features seen during each observation.\n       The features must be whitened first with the `whiten` function.\n\n    k_or_guess : int or ndarray\n       The number of centroids to generate. A code is assigned to\n       each centroid, which is also the row index of the centroid\n       in the code_book matrix generated.\n\n       The initial k centroids are chosen by randomly selecting\n       observations from the observation matrix. Alternatively,\n       passing a k by N array specifies the initial k centroids.\n\n    iter : int, optional\n       The number of times to run k-means, returning the codebook\n       with the lowest distortion. This argument is ignored if\n       initial centroids are specified with an array for the\n       ``k_or_guess`` parameter. This parameter does not represent the\n       number of iterations of the k-means algorithm.\n\n    thresh : float, optional\n       Terminates the k-means algorithm if the change in\n       distortion since the last k-means iteration is less than\n       or equal to thresh.\n\n    check_finite : bool, optional\n        Whether to check that the input matrices contain only finite numbers.\n        Disabling may give a performance gain, but may result in problems\n        (crashes, non-termination) if the inputs do contain infinities or NaNs.\n        Default: True\n\n    Returns\n    -------\n    codebook : ndarray\n       A k by N array of k centroids. The i'th centroid\n       codebook[i] is represented with the code i. The centroids\n       and codes generated represent the lowest distortion seen,\n       not necessarily the globally minimal distortion.\n\n    distortion : float\n       The distortion between the observations passed and the\n       centroids generated.\n\n    See Also\n    --------\n    kmeans2 : a different implementation of k-means clustering\n       with more methods for generating initial centroids but without\n       using a distortion change threshold as a stopping criterion.\n\n    whiten : must be called prior to passing an observation matrix\n       to kmeans.\n\n    Examples\n    --------\n    >>> from numpy import array\n    >>> from scipy.cluster.vq import vq, kmeans, whiten\n    >>> features  = array([[ 1.9,2.3],\n    ...                    [ 1.5,2.5],\n    ...                    [ 0.8,0.6],\n    ...                    [ 0.4,1.8],\n    ...                    [ 0.1,0.1],\n    ...                    [ 0.2,1.8],\n    ...                    [ 2.0,0.5],\n    ...                    [ 0.3,1.5],\n    ...                    [ 1.0,1.0]])\n    >>> whitened = whiten(features)\n    >>> book = np.array((whitened[0],whitened[2]))\n    >>> kmeans(whitened,book)\n    (array([[ 2.3110306 ,  2.86287398],    # random\n           [ 0.93218041,  1.24398691]]), 0.85684700941625547)\n\n    >>> from numpy import random\n    >>> random.seed((1000,2000))\n    >>> codes = 3\n    >>> kmeans(whitened,codes)\n    (array([[ 2.3110306 ,  2.86287398],    # random\n           [ 1.32544402,  0.65607529],\n           [ 0.40782893,  2.02786907]]), 0.5196582527686241)\n\n    "
obs = _asarray_validated(obs, check_finite=check_finite)
if (int(iter) < 1):
    raise ValueError('iter must be at least 1.')
k = None
guess = None
try:
    k = int(k_or_guess)
except TypeError:
    guess = _asarray_validated(k_or_guess, check_finite=check_finite)
if (guess is not None):
    if (guess.size < 1):
        raise ValueError(('Asked for 0 cluster ? initial book was %s' % guess))
    result = _kmeans(obs, guess, thresh=thresh)
else:
    if (k != k_or_guess):
        raise ValueError('if k_or_guess is a scalar, it must be an integer')
    best_dist = numpy.inf
    No = obs.shape[0]
    k = k_or_guess
    if (k < 1):
        raise ValueError('Asked for 0 cluster ? ')
    for i in range(iter):
        k_random_indices = numpy.random.randint(0, No, k)
        if numpy.any((scipy._lib._numpy_compat.unique(k_random_indices, return_counts=True)[1] > 1)):
            tempResult = permutation(No)
	
===================================================================	
_kpoints: 147	
----------------------------	

'Pick k points at random in data (one row = one observation).\n\n    This is done by taking the k first values of a random permutation of 1..N\n    where N is the number of observation.\n\n    Parameters\n    ----------\n    data : ndarray\n        Expect a rank 1 or 2 array. Rank 1 are assumed to describe one\n        dimensional data, rank 2 multidimensional data, in which case one\n        row is one observation.\n    k : int\n        Number of samples to generate.\n\n    '
if (data.ndim > 1):
    n = data.shape[0]
else:
    n = data.size
tempResult = permutation(n)
	
===================================================================	
TestIsIsomorphic.help_is_isomorphic_randperm: 230	
----------------------------	

for k in range(3):
    a = numpy.int_((numpy.random.rand(nobs) * nclusters))
    b = numpy.zeros(a.size, dtype=numpy.int_)
    tempResult = permutation(nclusters)
	
===================================================================	
TestIsIsomorphic.help_is_isomorphic_randperm: 234	
----------------------------	

for k in range(3):
    a = numpy.int_((numpy.random.rand(nobs) * nclusters))
    b = numpy.zeros(a.size, dtype=numpy.int_)
    P = numpy.random.permutation(nclusters)
    for i in xrange(0, a.shape[0]):
        b[i] = P[a[i]]
    if noniso:
        tempResult = permutation(nobs)
	
===================================================================	
test_graph_maximum_bipartite_matching: 30	
----------------------------	

A = diags(numpy.ones(25), offsets=0, format='csc')
tempResult = permutation(25)
	
===================================================================	
test_graph_maximum_bipartite_matching: 31	
----------------------------	

A = diags(numpy.ones(25), offsets=0, format='csc')
rand_perm = numpy.random.permutation(25)
tempResult = permutation(25)
	
===================================================================	
TestLevene.test_trimmed2: 356	
----------------------------	

x = [1.2, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 100.0]
y = [0.0, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 200.0]
numpy.random.seed(1234)
tempResult = permutation(x)
	
===================================================================	
TestLevene.test_equal_mean_median: 367	
----------------------------	

x = numpy.linspace((- 1), 1, 21)
numpy.random.seed(1234)
tempResult = permutation(x)
	
***************************************************	
sklearn_sklearn-0.18.0: 1	
===================================================================	
test_isotonic_regression: 62	
----------------------------	

y = numpy.array([3, 7, 5, 9, 8, 7, 10])
y_ = numpy.array([3, 6, 6, 8, 8, 8, 10])
assert_array_equal(y_, isotonic_regression(y))
y = numpy.array([10, 0, 2])
y_ = numpy.array([4, 4, 4])
assert_array_equal(y_, isotonic_regression(y))
x = numpy.arange(len(y))
ir = IsotonicRegression(y_min=0.0, y_max=1.0)
ir.fit(x, y)
assert_array_equal(ir.fit(x, y).transform(x), ir.fit_transform(x, y))
assert_array_equal(ir.transform(x), ir.predict(x))
tempResult = permutation(len(y))
	
***************************************************	
matplotlib_matplotlib-2.0.0: 0	
***************************************************	
ipython_ipython-6.1.0: 0	
***************************************************	
pandas_pandas-0.19.2: 29	
===================================================================	
TestCategorical.test_comparisons: 294	
----------------------------	

result = self.factor[(self.factor == 'a')]
expected = self.factor[(numpy.asarray(self.factor) == 'a')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor != 'a')]
expected = self.factor[(numpy.asarray(self.factor) != 'a')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor < 'c')]
expected = self.factor[(numpy.asarray(self.factor) < 'c')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor > 'a')]
expected = self.factor[(numpy.asarray(self.factor) > 'a')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor >= 'b')]
expected = self.factor[(numpy.asarray(self.factor) >= 'b')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor <= 'b')]
expected = self.factor[(numpy.asarray(self.factor) <= 'b')]
pandas.util.testing.assert_categorical_equal(result, expected)
n = len(self.factor)
tempResult = permutation(n)
	
===================================================================	
TestGroupBy.test_int64_overflow: 2452	
----------------------------	

from pandas.core.groupby import _int64_overflow_possible
B = numpy.concatenate((numpy.arange(1000), numpy.arange(1000), numpy.arange(500)))
A = numpy.arange(2500)
df = DataFrame({'A': A, 'B': B, 'C': A, 'D': B, 'E': A, 'F': B, 'G': A, 'H': B, 'values': numpy.random.randn(2500)})
lg = df.groupby(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])
rg = df.groupby(['H', 'G', 'F', 'E', 'D', 'C', 'B', 'A'])
left = lg.sum()['values']
right = rg.sum()['values']
(exp_index, _) = left.index.sortlevel(0)
self.assert_index_equal(left.index, exp_index)
(exp_index, _) = right.index.sortlevel(0)
self.assert_index_equal(right.index, exp_index)
tups = list(map(tuple, df[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']].values))
tups = pandas.core.common._asarray_tuplesafe(tups)
expected = df.groupby(tups).sum()['values']
for (k, v) in pandas.compat.iteritems(expected):
    self.assertEqual(left[k], right[k[::(- 1)]])
    self.assertEqual(left[k], v)
self.assertEqual(len(left), len(right))
values = range(55109)
data = pandas.DataFrame.from_dict({'a': values, 'b': values, 'c': values, 'd': values})
grouped = data.groupby(['a', 'b', 'c', 'd'])
self.assertEqual(len(grouped), len(values))
arr = numpy.random.randint(((- 1) << 12), (1 << 12), ((1 << 15), 5))
i = numpy.random.choice(len(arr), (len(arr) * 4))
arr = numpy.vstack((arr, arr[i]))
tempResult = permutation(len(arr))
	
===================================================================	
TestPanel.test_to_frame: 1126	
----------------------------	

filtered = self.panel.to_frame()
expected = self.panel.to_frame().dropna(how='any')
assert_frame_equal(filtered, expected)
unfiltered = self.panel.to_frame(filter_observations=False)
assert_panel_equal(unfiltered.to_panel(), self.panel)
self.assertEqual(unfiltered.index.names, ('major', 'minor'))
df = self.panel.to_frame(filter_observations=False)
tempResult = permutation(len(df))
	
===================================================================	
TestStyler.setUp: 23	
----------------------------	

numpy.random.seed(24)
tempResult = permutation(range(6))
	
===================================================================	
TestDataFrameAnalytics.test_nlargest: 832	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nlargest_multiple_columns: 839	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nlargest_multiple_columns: 839	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nsmallest_multiple_columns: 853	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nsmallest_multiple_columns: 853	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nsmallest: 846	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameSorting.test_sort_index_different_sortorder: 225	
----------------------------	

A = np.arange(20).repeat(5)
B = numpy.tile(numpy.arange(5), 20)
tempResult = permutation(100)
	
===================================================================	
TestIndex.test_outer_join_sort: 1004	
----------------------------	

tempResult = permutation(15)
	
===================================================================	
TestMultiIndex.test_duplicates: 1417	
----------------------------	

self.assertFalse(self.index.has_duplicates)
self.assertTrue(self.index.append(self.index).has_duplicates)
index = MultiIndex(levels=[[0, 1], [0, 1, 2]], labels=[[0, 0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 0, 1, 2]])
self.assertTrue(index.has_duplicates)
t = [(u('x'), u('out'), u('z'), 5, u('y'), u('in'), u('z'), 169), (u('x'), u('out'), u('z'), 7, u('y'), u('in'), u('z'), 119), (u('x'), u('out'), u('z'), 9, u('y'), u('in'), u('z'), 135), (u('x'), u('out'), u('z'), 13, u('y'), u('in'), u('z'), 145), (u('x'), u('out'), u('z'), 14, u('y'), u('in'), u('z'), 158), (u('x'), u('out'), u('z'), 16, u('y'), u('in'), u('z'), 122), (u('x'), u('out'), u('z'), 17, u('y'), u('in'), u('z'), 160), (u('x'), u('out'), u('z'), 18, u('y'), u('in'), u('z'), 180), (u('x'), u('out'), u('z'), 20, u('y'), u('in'), u('z'), 143), (u('x'), u('out'), u('z'), 21, u('y'), u('in'), u('z'), 128), (u('x'), u('out'), u('z'), 22, u('y'), u('in'), u('z'), 129), (u('x'), u('out'), u('z'), 25, u('y'), u('in'), u('z'), 111), (u('x'), u('out'), u('z'), 28, u('y'), u('in'), u('z'), 114), (u('x'), u('out'), u('z'), 29, u('y'), u('in'), u('z'), 121), (u('x'), u('out'), u('z'), 31, u('y'), u('in'), u('z'), 126), (u('x'), u('out'), u('z'), 32, u('y'), u('in'), u('z'), 155), (u('x'), u('out'), u('z'), 33, u('y'), u('in'), u('z'), 123), (u('x'), u('out'), u('z'), 12, u('y'), u('in'), u('z'), 144)]
index = pandas.MultiIndex.from_tuples(t)
self.assertFalse(index.has_duplicates)

def check(nlevels, with_nulls):
    labels = numpy.tile(numpy.arange(500), 2)
    level = numpy.arange(500)
    if with_nulls:
        labels[500] = (- 1)
        labels = list((labels.copy() for i in range(nlevels)))
        for i in range(nlevels):
            labels[i][((500 + i) - (nlevels // 2))] = (- 1)
        labels += [np.array([(- 1), 1]).repeat(500)]
    else:
        labels = (([labels] * nlevels) + [np.arange(2).repeat(500)])
    levels = (([level] * nlevels) + [[0, 1]])
    index = MultiIndex(levels=levels, labels=labels)
    self.assertFalse(index.has_duplicates)
    if with_nulls:
        f = (lambda a: numpy.insert(a, 1000, a[0]))
        labels = list(map(f, labels))
        index = MultiIndex(levels=levels, labels=labels)
    else:
        values = index.values.tolist()
        index = pandas.MultiIndex.from_tuples((values + [values[0]]))
    self.assertTrue(index.has_duplicates)
check(4, False)
check(4, True)
check(8, False)
check(8, True)
(n, k) = (200, 5000)
levels = [numpy.arange(n), pandas.util.testing.makeStringIndex(n), (1000 + numpy.arange(n))]
labels = [numpy.random.choice(n, (k * n)) for lev in levels]
mi = MultiIndex(levels=levels, labels=labels)
for keep in ['first', 'last', False]:
    left = mi.duplicated(keep=keep)
    right = pandas.hashtable.duplicated_object(mi.values, keep=keep)
    pandas.util.testing.assert_numpy_array_equal(left, right)
for a in [101, 102]:
    mi = pandas.MultiIndex.from_arrays([[101, a], [3.5, numpy.nan]])
    self.assertFalse(mi.has_duplicates)
    self.assertEqual(mi.get_duplicates(), [])
    pandas.util.testing.assert_numpy_array_equal(mi.duplicated(), numpy.zeros(2, dtype='bool'))
for n in range(1, 6):
    for m in range(1, 5):
        lab = product(range((- 1), n), range((- 1), m))
        tempResult = permutation(list(lab))
	
===================================================================	
TestSeriesAnalytics.test_rank_inf: 700	
----------------------------	

raise nose.SkipTest('DataFrame.rank does not currently rank np.inf and -np.inf properly')
values = numpy.array([(- numpy.inf), (- 50), (- 1), (- 1e-20), (- 1e-25), (- 1e-50), 0, 1e-40, 1e-20, 1e-10, 2, 40, numpy.inf], dtype='float64')
tempResult = permutation(len(values))
	
===================================================================	
TestSeriesAnalytics.test_rank: 686	
----------------------------	

pandas.util.testing._skip_if_no_scipy()
from scipy.stats import rankdata
self.ts[::2] = numpy.nan
self.ts[:10][::3] = 4.0
ranks = self.ts.rank()
oranks = self.ts.astype('O').rank()
assert_series_equal(ranks, oranks)
mask = numpy.isnan(self.ts)
filled = self.ts.fillna(numpy.inf)
exp = Series(rankdata(filled), index=filled.index, name='ts')
exp[mask] = numpy.nan
pandas.util.testing.assert_series_equal(ranks, exp)
iseries = Series(np.arange(5).repeat(2))
iranks = iseries.rank()
exp = iseries.astype(float).rank()
assert_series_equal(iranks, exp)
iseries = (Series(numpy.arange(5)) + 1.0)
exp = (iseries / 5.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = Series(numpy.repeat(1, 100))
exp = Series(numpy.repeat(0.505, 100))
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries[1] = numpy.nan
exp = Series(numpy.repeat((50.0 / 99.0), 100))
exp[1] = numpy.nan
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = (Series(numpy.arange(5)) + 1.0)
iseries[4] = numpy.nan
exp = (iseries / 4.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = Series(numpy.repeat(numpy.nan, 100))
exp = iseries.copy()
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = (Series(numpy.arange(5)) + 1)
iseries[4] = numpy.nan
exp = (iseries / 4.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
rng = date_range('1/1/1990', periods=5)
iseries = (Series(numpy.arange(5), rng) + 1)
iseries.ix[4] = numpy.nan
exp = (iseries / 4.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = Series([1e-50, 1e-100, 1e-20, 0.01, (1e-20 + 1e-30), 0.1])
exp = Series([2, 1, 3, 5, 4, 6.0])
iranks = iseries.rank()
assert_series_equal(iranks, exp)
iseries = Series(['3 day', '1 day 10m', '-2 day', pandas.NaT], dtype='m8[ns]')
exp = Series([3, 2, 1, numpy.nan])
iranks = iseries.rank()
assert_series_equal(iranks, exp)
values = numpy.array([(- 50), (- 1), (- 1e-20), (- 1e-25), (- 1e-50), 0, 1e-40, 1e-20, 1e-10, 2, 40], dtype='float64')
tempResult = permutation(len(values))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 613	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 642	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 645	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
i = numpy.random.permutation(len(left))
left = left.iloc[i].copy()
left.index = numpy.arange(len(left))
tempResult = permutation(len(right))
	
===================================================================	
_permute: 2774	
----------------------------	

tempResult = permutation(len(obj))
	
===================================================================	
TestDatetimeIndex.test_resample_not_monotonic: 1075	
----------------------------	

rng = pandas.date_range('2012-06-12', periods=200, freq='h')
ts = Series(numpy.random.randn(len(rng)), index=rng)
tempResult = permutation(len(ts))
	
===================================================================	
TestSlicing.test_min_max: 3490	
----------------------------	

rng = date_range('1/1/2000', '12/31/2000')
tempResult = permutation(len(rng))
	
===================================================================	
TestTimeSeriesDuplicates.test_indexing_unordered: 163	
----------------------------	

rng = date_range(start='2011-01-01', end='2011-01-15')
ts = Series(randn(len(rng)), index=rng)
ts2 = concat([ts[0:4], ts[(- 4):], ts[4:(- 4)]])
for t in ts.index:
    s = str(t)
    expected = ts[t]
    result = ts2[t]
    self.assertTrue((expected == result))

def compare(slobj):
    result = ts2[slobj].copy()
    result = result.sort_index()
    expected = ts[slobj]
    assert_series_equal(result, expected)
compare(slice('2011-01-01', '2011-01-15'))
compare(slice('2010-12-30', '2011-01-15'))
compare(slice('2011-01-01', '2011-01-16'))
compare(slice('2011-01-01', '2011-01-6'))
compare(slice('2011-01-06', '2011-01-8'))
compare(slice('2011-01-06', '2011-01-12'))
result = ts2['2011'].sort_index()
expected = ts['2011']
assert_series_equal(result, expected)
rng = date_range(datetime(2005, 1, 1), periods=20, freq='M')
ts = Series(numpy.arange(len(rng)), index=rng)
tempResult = permutation(20)
	
===================================================================	
TestTimeZones.test_arith_utc_convert: 1019	
----------------------------	

rng = date_range('1/1/2011', periods=100, freq='H', tz='utc')
tempResult = permutation(100)
	
===================================================================	
TestTimeZones.test_arith_utc_convert: 1021	
----------------------------	

rng = date_range('1/1/2011', periods=100, freq='H', tz='utc')
perm = numpy.random.permutation(100)[:90]
ts1 = Series(numpy.random.randn(90), index=rng.take(perm).tz_convert('US/Eastern'))
tempResult = permutation(100)
	
===================================================================	
TestGroupBy.test_int64_overflow: 2452	
----------------------------	

from pandas.core.groupby import _int64_overflow_possible
B = numpy.concatenate((numpy.arange(1000), numpy.arange(1000), numpy.arange(500)))
A = numpy.arange(2500)
df = DataFrame({'A': A, 'B': B, 'C': A, 'D': B, 'E': A, 'F': B, 'G': A, 'H': B, 'values': numpy.random.randn(2500)})
lg = df.groupby(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])
rg = df.groupby(['H', 'G', 'F', 'E', 'D', 'C', 'B', 'A'])
left = lg.sum()['values']
right = rg.sum()['values']
(exp_index, _) = left.index.sortlevel(0)
self.assert_index_equal(left.index, exp_index)
(exp_index, _) = right.index.sortlevel(0)
self.assert_index_equal(right.index, exp_index)
tups = list(map(tuple, df[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']].values))
tups = pandas.core.common._asarray_tuplesafe(tups)
expected = df.groupby(tups).sum()['values']
for (k, v) in pandas.compat.iteritems(expected):
    self.assertEqual(left[k], right[k[::(- 1)]])
    self.assertEqual(left[k], v)
self.assertEqual(len(left), len(right))
values = range(55109)
data = pandas.DataFrame.from_dict({'a': values, 'b': values, 'c': values, 'd': values})
grouped = data.groupby(['a', 'b', 'c', 'd'])
self.assertEqual(len(grouped), len(values))
arr = numpy.random.randint(((- 1) << 12), (1 << 12), ((1 << 15), 5))
i = numpy.random.choice(len(arr), (len(arr) * 4))
arr = numpy.vstack((arr, arr[i]))
tempResult = permutation(len(arr))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 613	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 642	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 645	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
i = numpy.random.permutation(len(left))
left = left.iloc[i].copy()
left.index = numpy.arange(len(left))
tempResult = permutation(len(right))
	
===================================================================	
TestDatetimeIndex.test_resample_not_monotonic: 1075	
----------------------------	

rng = pandas.date_range('2012-06-12', periods=200, freq='h')
ts = Series(numpy.random.randn(len(rng)), index=rng)
tempResult = permutation(len(ts))
	
***************************************************	
dask_dask-0.7.0: 0	
***************************************************	
nengo_nengo-2.0.0: 0	
***************************************************	
sympy_sympy-1.0.0: 0	
***************************************************	
daducci_amico-dev: 0	
***************************************************	
aplpy_aplpy-1.1.1: 0	
***************************************************	
markovmodel_msmtools-1.0.2: 0	
***************************************************	
nilearn_nilearn-0.4.0: 1	
===================================================================	
test_searchlight: 56	
----------------------------	

rand = numpy.random.RandomState(0)
frames = 30
data = rand.rand(5, 5, 5, frames)
mask = numpy.ones((5, 5, 5), numpy.bool)
mask_img = nibabel.Nifti1Image(mask.astype(numpy.int), numpy.eye(4))
cond = (numpy.arange(frames, dtype=int) > (frames // 2))
data[2, 2, 2, :] = 0
data[(2, 2, 2)][cond.astype(numpy.bool)] = 2
data_img = nibabel.Nifti1Image(data, numpy.eye(4))
if (LooseVersion(sklearn.__version__) >= LooseVersion('0.18')):
    from sklearn.model_selection import KFold
    cv = KFold(n_splits=4)
else:
    from sklearn.cross_validation import KFold
    cv = KFold(len(cond), 4)
n_jobs = 1
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=mask_img, radius=0.5, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 1)
assert_equal(sl.scores_[(2, 2, 2)], 1.0)
process_mask = numpy.zeros((5, 5, 5), numpy.bool)
process_mask[(0, 0, 0)] = True
process_mask_img = nibabel.Nifti1Image(process_mask.astype(numpy.int), numpy.eye(4))
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=process_mask_img, radius=0.5, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 0)
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=mask_img, radius=1, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 7)
assert_equal(sl.scores_[(2, 2, 2)], 1.0)
assert_equal(sl.scores_[(1, 2, 2)], 1.0)
assert_equal(sl.scores_[(2, 1, 2)], 1.0)
assert_equal(sl.scores_[(2, 2, 1)], 1.0)
assert_equal(sl.scores_[(3, 2, 2)], 1.0)
assert_equal(sl.scores_[(2, 3, 2)], 1.0)
assert_equal(sl.scores_[(2, 2, 3)], 1.0)
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=mask_img, radius=2, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 33)
assert_equal(sl.scores_[(2, 2, 2)], 1.0)
try:
    from sklearn.model_selection import LeaveOneGroupOut
    gcv = LeaveOneGroupOut()
except ImportError:
    gcv = cv
tempResult = permutation((numpy.arange(frames, dtype=int) > (frames // 2)))
	
***************************************************	
poliastro_poliastro-0.8.0: 0	
***************************************************	
skimage_skimage-0.13.0: 0	
***************************************************	
sunpy_sunpy-0.8.0: 0	
***************************************************	
spacetelescope_synphot-0.1: 0	
***************************************************	
librosa_librosa-0.5.1: 0	
***************************************************	
mne_python-0.15.0: 0	
***************************************************	
astropy_astropy-1.3.0: 0	
***************************************************	
scipy_scipy-0.19.0: 8	
===================================================================	
kmeans: 132	
----------------------------	

"\n    Performs k-means on a set of observation vectors forming k clusters.\n\n    The k-means algorithm adjusts the centroids until sufficient\n    progress cannot be made, i.e. the change in distortion since\n    the last iteration is less than some threshold. This yields\n    a code book mapping centroids to codes and vice versa.\n\n    Distortion is defined as the sum of the squared differences\n    between the observations and the corresponding centroid.\n\n    Parameters\n    ----------\n    obs : ndarray\n       Each row of the M by N array is an observation vector. The\n       columns are the features seen during each observation.\n       The features must be whitened first with the `whiten` function.\n\n    k_or_guess : int or ndarray\n       The number of centroids to generate. A code is assigned to\n       each centroid, which is also the row index of the centroid\n       in the code_book matrix generated.\n\n       The initial k centroids are chosen by randomly selecting\n       observations from the observation matrix. Alternatively,\n       passing a k by N array specifies the initial k centroids.\n\n    iter : int, optional\n       The number of times to run k-means, returning the codebook\n       with the lowest distortion. This argument is ignored if\n       initial centroids are specified with an array for the\n       ``k_or_guess`` parameter. This parameter does not represent the\n       number of iterations of the k-means algorithm.\n\n    thresh : float, optional\n       Terminates the k-means algorithm if the change in\n       distortion since the last k-means iteration is less than\n       or equal to thresh.\n\n    check_finite : bool, optional\n        Whether to check that the input matrices contain only finite numbers.\n        Disabling may give a performance gain, but may result in problems\n        (crashes, non-termination) if the inputs do contain infinities or NaNs.\n        Default: True\n\n    Returns\n    -------\n    codebook : ndarray\n       A k by N array of k centroids. The i'th centroid\n       codebook[i] is represented with the code i. The centroids\n       and codes generated represent the lowest distortion seen,\n       not necessarily the globally minimal distortion.\n\n    distortion : float\n       The distortion between the observations passed and the\n       centroids generated.\n\n    See Also\n    --------\n    kmeans2 : a different implementation of k-means clustering\n       with more methods for generating initial centroids but without\n       using a distortion change threshold as a stopping criterion.\n\n    whiten : must be called prior to passing an observation matrix\n       to kmeans.\n\n    Examples\n    --------\n    >>> from numpy import array\n    >>> from scipy.cluster.vq import vq, kmeans, whiten\n    >>> features  = array([[ 1.9,2.3],\n    ...                    [ 1.5,2.5],\n    ...                    [ 0.8,0.6],\n    ...                    [ 0.4,1.8],\n    ...                    [ 0.1,0.1],\n    ...                    [ 0.2,1.8],\n    ...                    [ 2.0,0.5],\n    ...                    [ 0.3,1.5],\n    ...                    [ 1.0,1.0]])\n    >>> whitened = whiten(features)\n    >>> book = np.array((whitened[0],whitened[2]))\n    >>> kmeans(whitened,book)\n    (array([[ 2.3110306 ,  2.86287398],    # random\n           [ 0.93218041,  1.24398691]]), 0.85684700941625547)\n\n    >>> from numpy import random\n    >>> random.seed((1000,2000))\n    >>> codes = 3\n    >>> kmeans(whitened,codes)\n    (array([[ 2.3110306 ,  2.86287398],    # random\n           [ 1.32544402,  0.65607529],\n           [ 0.40782893,  2.02786907]]), 0.5196582527686241)\n\n    "
obs = _asarray_validated(obs, check_finite=check_finite)
if (int(iter) < 1):
    raise ValueError('iter must be at least 1.')
k = None
guess = None
try:
    k = int(k_or_guess)
except TypeError:
    guess = _asarray_validated(k_or_guess, check_finite=check_finite)
if (guess is not None):
    if (guess.size < 1):
        raise ValueError(('Asked for 0 cluster ? initial book was %s' % guess))
    result = _kmeans(obs, guess, thresh=thresh)
else:
    if (k != k_or_guess):
        raise ValueError('if k_or_guess is a scalar, it must be an integer')
    best_dist = numpy.inf
    No = obs.shape[0]
    k = k_or_guess
    if (k < 1):
        raise ValueError('Asked for 0 cluster ? ')
    for i in range(iter):
        k_random_indices = numpy.random.randint(0, No, k)
        if numpy.any((scipy._lib._numpy_compat.unique(k_random_indices, return_counts=True)[1] > 1)):
            tempResult = permutation(No)
	
===================================================================	
_kpoints: 147	
----------------------------	

'Pick k points at random in data (one row = one observation).\n\n    This is done by taking the k first values of a random permutation of 1..N\n    where N is the number of observation.\n\n    Parameters\n    ----------\n    data : ndarray\n        Expect a rank 1 or 2 array. Rank 1 are assumed to describe one\n        dimensional data, rank 2 multidimensional data, in which case one\n        row is one observation.\n    k : int\n        Number of samples to generate.\n\n    '
if (data.ndim > 1):
    n = data.shape[0]
else:
    n = data.size
tempResult = permutation(n)
	
===================================================================	
TestIsIsomorphic.help_is_isomorphic_randperm: 230	
----------------------------	

for k in range(3):
    a = numpy.int_((numpy.random.rand(nobs) * nclusters))
    b = numpy.zeros(a.size, dtype=numpy.int_)
    tempResult = permutation(nclusters)
	
===================================================================	
TestIsIsomorphic.help_is_isomorphic_randperm: 234	
----------------------------	

for k in range(3):
    a = numpy.int_((numpy.random.rand(nobs) * nclusters))
    b = numpy.zeros(a.size, dtype=numpy.int_)
    P = numpy.random.permutation(nclusters)
    for i in xrange(0, a.shape[0]):
        b[i] = P[a[i]]
    if noniso:
        tempResult = permutation(nobs)
	
===================================================================	
test_graph_maximum_bipartite_matching: 30	
----------------------------	

A = diags(numpy.ones(25), offsets=0, format='csc')
tempResult = permutation(25)
	
===================================================================	
test_graph_maximum_bipartite_matching: 31	
----------------------------	

A = diags(numpy.ones(25), offsets=0, format='csc')
rand_perm = numpy.random.permutation(25)
tempResult = permutation(25)
	
===================================================================	
TestLevene.test_trimmed2: 356	
----------------------------	

x = [1.2, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 100.0]
y = [0.0, 3.0, 3.5, 4.0, 4.5, 5.0, 5.5, 200.0]
numpy.random.seed(1234)
tempResult = permutation(x)
	
===================================================================	
TestLevene.test_equal_mean_median: 367	
----------------------------	

x = numpy.linspace((- 1), 1, 21)
numpy.random.seed(1234)
tempResult = permutation(x)
	
***************************************************	
sklearn_sklearn-0.18.0: 1	
===================================================================	
test_isotonic_regression: 62	
----------------------------	

y = numpy.array([3, 7, 5, 9, 8, 7, 10])
y_ = numpy.array([3, 6, 6, 8, 8, 8, 10])
assert_array_equal(y_, isotonic_regression(y))
y = numpy.array([10, 0, 2])
y_ = numpy.array([4, 4, 4])
assert_array_equal(y_, isotonic_regression(y))
x = numpy.arange(len(y))
ir = IsotonicRegression(y_min=0.0, y_max=1.0)
ir.fit(x, y)
assert_array_equal(ir.fit(x, y).transform(x), ir.fit_transform(x, y))
assert_array_equal(ir.transform(x), ir.predict(x))
tempResult = permutation(len(y))
	
***************************************************	
matplotlib_matplotlib-2.0.0: 0	
***************************************************	
ipython_ipython-6.1.0: 0	
***************************************************	
pandas_pandas-0.19.2: 29	
===================================================================	
TestCategorical.test_comparisons: 294	
----------------------------	

result = self.factor[(self.factor == 'a')]
expected = self.factor[(numpy.asarray(self.factor) == 'a')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor != 'a')]
expected = self.factor[(numpy.asarray(self.factor) != 'a')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor < 'c')]
expected = self.factor[(numpy.asarray(self.factor) < 'c')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor > 'a')]
expected = self.factor[(numpy.asarray(self.factor) > 'a')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor >= 'b')]
expected = self.factor[(numpy.asarray(self.factor) >= 'b')]
pandas.util.testing.assert_categorical_equal(result, expected)
result = self.factor[(self.factor <= 'b')]
expected = self.factor[(numpy.asarray(self.factor) <= 'b')]
pandas.util.testing.assert_categorical_equal(result, expected)
n = len(self.factor)
tempResult = permutation(n)
	
===================================================================	
TestGroupBy.test_int64_overflow: 2452	
----------------------------	

from pandas.core.groupby import _int64_overflow_possible
B = numpy.concatenate((numpy.arange(1000), numpy.arange(1000), numpy.arange(500)))
A = numpy.arange(2500)
df = DataFrame({'A': A, 'B': B, 'C': A, 'D': B, 'E': A, 'F': B, 'G': A, 'H': B, 'values': numpy.random.randn(2500)})
lg = df.groupby(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])
rg = df.groupby(['H', 'G', 'F', 'E', 'D', 'C', 'B', 'A'])
left = lg.sum()['values']
right = rg.sum()['values']
(exp_index, _) = left.index.sortlevel(0)
self.assert_index_equal(left.index, exp_index)
(exp_index, _) = right.index.sortlevel(0)
self.assert_index_equal(right.index, exp_index)
tups = list(map(tuple, df[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']].values))
tups = pandas.core.common._asarray_tuplesafe(tups)
expected = df.groupby(tups).sum()['values']
for (k, v) in pandas.compat.iteritems(expected):
    self.assertEqual(left[k], right[k[::(- 1)]])
    self.assertEqual(left[k], v)
self.assertEqual(len(left), len(right))
values = range(55109)
data = pandas.DataFrame.from_dict({'a': values, 'b': values, 'c': values, 'd': values})
grouped = data.groupby(['a', 'b', 'c', 'd'])
self.assertEqual(len(grouped), len(values))
arr = numpy.random.randint(((- 1) << 12), (1 << 12), ((1 << 15), 5))
i = numpy.random.choice(len(arr), (len(arr) * 4))
arr = numpy.vstack((arr, arr[i]))
tempResult = permutation(len(arr))
	
===================================================================	
TestPanel.test_to_frame: 1126	
----------------------------	

filtered = self.panel.to_frame()
expected = self.panel.to_frame().dropna(how='any')
assert_frame_equal(filtered, expected)
unfiltered = self.panel.to_frame(filter_observations=False)
assert_panel_equal(unfiltered.to_panel(), self.panel)
self.assertEqual(unfiltered.index.names, ('major', 'minor'))
df = self.panel.to_frame(filter_observations=False)
tempResult = permutation(len(df))
	
===================================================================	
TestStyler.setUp: 23	
----------------------------	

numpy.random.seed(24)
tempResult = permutation(range(6))
	
===================================================================	
TestDataFrameAnalytics.test_nlargest: 832	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nlargest_multiple_columns: 839	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nlargest_multiple_columns: 839	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nsmallest_multiple_columns: 853	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nsmallest_multiple_columns: 853	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameAnalytics.test_nsmallest: 846	
----------------------------	

from string import ascii_lowercase
tempResult = permutation(10)
	
===================================================================	
TestDataFrameSorting.test_sort_index_different_sortorder: 225	
----------------------------	

A = np.arange(20).repeat(5)
B = numpy.tile(numpy.arange(5), 20)
tempResult = permutation(100)
	
===================================================================	
TestIndex.test_outer_join_sort: 1004	
----------------------------	

tempResult = permutation(15)
	
===================================================================	
TestMultiIndex.test_duplicates: 1417	
----------------------------	

self.assertFalse(self.index.has_duplicates)
self.assertTrue(self.index.append(self.index).has_duplicates)
index = MultiIndex(levels=[[0, 1], [0, 1, 2]], labels=[[0, 0, 0, 0, 1, 1, 1], [0, 1, 2, 0, 0, 1, 2]])
self.assertTrue(index.has_duplicates)
t = [(u('x'), u('out'), u('z'), 5, u('y'), u('in'), u('z'), 169), (u('x'), u('out'), u('z'), 7, u('y'), u('in'), u('z'), 119), (u('x'), u('out'), u('z'), 9, u('y'), u('in'), u('z'), 135), (u('x'), u('out'), u('z'), 13, u('y'), u('in'), u('z'), 145), (u('x'), u('out'), u('z'), 14, u('y'), u('in'), u('z'), 158), (u('x'), u('out'), u('z'), 16, u('y'), u('in'), u('z'), 122), (u('x'), u('out'), u('z'), 17, u('y'), u('in'), u('z'), 160), (u('x'), u('out'), u('z'), 18, u('y'), u('in'), u('z'), 180), (u('x'), u('out'), u('z'), 20, u('y'), u('in'), u('z'), 143), (u('x'), u('out'), u('z'), 21, u('y'), u('in'), u('z'), 128), (u('x'), u('out'), u('z'), 22, u('y'), u('in'), u('z'), 129), (u('x'), u('out'), u('z'), 25, u('y'), u('in'), u('z'), 111), (u('x'), u('out'), u('z'), 28, u('y'), u('in'), u('z'), 114), (u('x'), u('out'), u('z'), 29, u('y'), u('in'), u('z'), 121), (u('x'), u('out'), u('z'), 31, u('y'), u('in'), u('z'), 126), (u('x'), u('out'), u('z'), 32, u('y'), u('in'), u('z'), 155), (u('x'), u('out'), u('z'), 33, u('y'), u('in'), u('z'), 123), (u('x'), u('out'), u('z'), 12, u('y'), u('in'), u('z'), 144)]
index = pandas.MultiIndex.from_tuples(t)
self.assertFalse(index.has_duplicates)

def check(nlevels, with_nulls):
    labels = numpy.tile(numpy.arange(500), 2)
    level = numpy.arange(500)
    if with_nulls:
        labels[500] = (- 1)
        labels = list((labels.copy() for i in range(nlevels)))
        for i in range(nlevels):
            labels[i][((500 + i) - (nlevels // 2))] = (- 1)
        labels += [np.array([(- 1), 1]).repeat(500)]
    else:
        labels = (([labels] * nlevels) + [np.arange(2).repeat(500)])
    levels = (([level] * nlevels) + [[0, 1]])
    index = MultiIndex(levels=levels, labels=labels)
    self.assertFalse(index.has_duplicates)
    if with_nulls:
        f = (lambda a: numpy.insert(a, 1000, a[0]))
        labels = list(map(f, labels))
        index = MultiIndex(levels=levels, labels=labels)
    else:
        values = index.values.tolist()
        index = pandas.MultiIndex.from_tuples((values + [values[0]]))
    self.assertTrue(index.has_duplicates)
check(4, False)
check(4, True)
check(8, False)
check(8, True)
(n, k) = (200, 5000)
levels = [numpy.arange(n), pandas.util.testing.makeStringIndex(n), (1000 + numpy.arange(n))]
labels = [numpy.random.choice(n, (k * n)) for lev in levels]
mi = MultiIndex(levels=levels, labels=labels)
for keep in ['first', 'last', False]:
    left = mi.duplicated(keep=keep)
    right = pandas.hashtable.duplicated_object(mi.values, keep=keep)
    pandas.util.testing.assert_numpy_array_equal(left, right)
for a in [101, 102]:
    mi = pandas.MultiIndex.from_arrays([[101, a], [3.5, numpy.nan]])
    self.assertFalse(mi.has_duplicates)
    self.assertEqual(mi.get_duplicates(), [])
    pandas.util.testing.assert_numpy_array_equal(mi.duplicated(), numpy.zeros(2, dtype='bool'))
for n in range(1, 6):
    for m in range(1, 5):
        lab = product(range((- 1), n), range((- 1), m))
        tempResult = permutation(list(lab))
	
===================================================================	
TestSeriesAnalytics.test_rank_inf: 700	
----------------------------	

raise nose.SkipTest('DataFrame.rank does not currently rank np.inf and -np.inf properly')
values = numpy.array([(- numpy.inf), (- 50), (- 1), (- 1e-20), (- 1e-25), (- 1e-50), 0, 1e-40, 1e-20, 1e-10, 2, 40, numpy.inf], dtype='float64')
tempResult = permutation(len(values))
	
===================================================================	
TestSeriesAnalytics.test_rank: 686	
----------------------------	

pandas.util.testing._skip_if_no_scipy()
from scipy.stats import rankdata
self.ts[::2] = numpy.nan
self.ts[:10][::3] = 4.0
ranks = self.ts.rank()
oranks = self.ts.astype('O').rank()
assert_series_equal(ranks, oranks)
mask = numpy.isnan(self.ts)
filled = self.ts.fillna(numpy.inf)
exp = Series(rankdata(filled), index=filled.index, name='ts')
exp[mask] = numpy.nan
pandas.util.testing.assert_series_equal(ranks, exp)
iseries = Series(np.arange(5).repeat(2))
iranks = iseries.rank()
exp = iseries.astype(float).rank()
assert_series_equal(iranks, exp)
iseries = (Series(numpy.arange(5)) + 1.0)
exp = (iseries / 5.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = Series(numpy.repeat(1, 100))
exp = Series(numpy.repeat(0.505, 100))
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries[1] = numpy.nan
exp = Series(numpy.repeat((50.0 / 99.0), 100))
exp[1] = numpy.nan
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = (Series(numpy.arange(5)) + 1.0)
iseries[4] = numpy.nan
exp = (iseries / 4.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = Series(numpy.repeat(numpy.nan, 100))
exp = iseries.copy()
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = (Series(numpy.arange(5)) + 1)
iseries[4] = numpy.nan
exp = (iseries / 4.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
rng = date_range('1/1/1990', periods=5)
iseries = (Series(numpy.arange(5), rng) + 1)
iseries.ix[4] = numpy.nan
exp = (iseries / 4.0)
iranks = iseries.rank(pct=True)
assert_series_equal(iranks, exp)
iseries = Series([1e-50, 1e-100, 1e-20, 0.01, (1e-20 + 1e-30), 0.1])
exp = Series([2, 1, 3, 5, 4, 6.0])
iranks = iseries.rank()
assert_series_equal(iranks, exp)
iseries = Series(['3 day', '1 day 10m', '-2 day', pandas.NaT], dtype='m8[ns]')
exp = Series([3, 2, 1, numpy.nan])
iranks = iseries.rank()
assert_series_equal(iranks, exp)
values = numpy.array([(- 50), (- 1), (- 1e-20), (- 1e-25), (- 1e-50), 0, 1e-40, 1e-20, 1e-10, 2, 40], dtype='float64')
tempResult = permutation(len(values))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 613	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 642	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 645	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
i = numpy.random.permutation(len(left))
left = left.iloc[i].copy()
left.index = numpy.arange(len(left))
tempResult = permutation(len(right))
	
===================================================================	
_permute: 2774	
----------------------------	

tempResult = permutation(len(obj))
	
===================================================================	
TestDatetimeIndex.test_resample_not_monotonic: 1075	
----------------------------	

rng = pandas.date_range('2012-06-12', periods=200, freq='h')
ts = Series(numpy.random.randn(len(rng)), index=rng)
tempResult = permutation(len(ts))
	
===================================================================	
TestSlicing.test_min_max: 3490	
----------------------------	

rng = date_range('1/1/2000', '12/31/2000')
tempResult = permutation(len(rng))
	
===================================================================	
TestTimeSeriesDuplicates.test_indexing_unordered: 163	
----------------------------	

rng = date_range(start='2011-01-01', end='2011-01-15')
ts = Series(randn(len(rng)), index=rng)
ts2 = concat([ts[0:4], ts[(- 4):], ts[4:(- 4)]])
for t in ts.index:
    s = str(t)
    expected = ts[t]
    result = ts2[t]
    self.assertTrue((expected == result))

def compare(slobj):
    result = ts2[slobj].copy()
    result = result.sort_index()
    expected = ts[slobj]
    assert_series_equal(result, expected)
compare(slice('2011-01-01', '2011-01-15'))
compare(slice('2010-12-30', '2011-01-15'))
compare(slice('2011-01-01', '2011-01-16'))
compare(slice('2011-01-01', '2011-01-6'))
compare(slice('2011-01-06', '2011-01-8'))
compare(slice('2011-01-06', '2011-01-12'))
result = ts2['2011'].sort_index()
expected = ts['2011']
assert_series_equal(result, expected)
rng = date_range(datetime(2005, 1, 1), periods=20, freq='M')
ts = Series(numpy.arange(len(rng)), index=rng)
tempResult = permutation(20)
	
===================================================================	
TestTimeZones.test_arith_utc_convert: 1019	
----------------------------	

rng = date_range('1/1/2011', periods=100, freq='H', tz='utc')
tempResult = permutation(100)
	
===================================================================	
TestTimeZones.test_arith_utc_convert: 1021	
----------------------------	

rng = date_range('1/1/2011', periods=100, freq='H', tz='utc')
perm = numpy.random.permutation(100)[:90]
ts1 = Series(numpy.random.randn(90), index=rng.take(perm).tz_convert('US/Eastern'))
tempResult = permutation(100)
	
===================================================================	
TestGroupBy.test_int64_overflow: 2452	
----------------------------	

from pandas.core.groupby import _int64_overflow_possible
B = numpy.concatenate((numpy.arange(1000), numpy.arange(1000), numpy.arange(500)))
A = numpy.arange(2500)
df = DataFrame({'A': A, 'B': B, 'C': A, 'D': B, 'E': A, 'F': B, 'G': A, 'H': B, 'values': numpy.random.randn(2500)})
lg = df.groupby(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H'])
rg = df.groupby(['H', 'G', 'F', 'E', 'D', 'C', 'B', 'A'])
left = lg.sum()['values']
right = rg.sum()['values']
(exp_index, _) = left.index.sortlevel(0)
self.assert_index_equal(left.index, exp_index)
(exp_index, _) = right.index.sortlevel(0)
self.assert_index_equal(right.index, exp_index)
tups = list(map(tuple, df[['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']].values))
tups = pandas.core.common._asarray_tuplesafe(tups)
expected = df.groupby(tups).sum()['values']
for (k, v) in pandas.compat.iteritems(expected):
    self.assertEqual(left[k], right[k[::(- 1)]])
    self.assertEqual(left[k], v)
self.assertEqual(len(left), len(right))
values = range(55109)
data = pandas.DataFrame.from_dict({'a': values, 'b': values, 'c': values, 'd': values})
grouped = data.groupby(['a', 'b', 'c', 'd'])
self.assertEqual(len(grouped), len(values))
arr = numpy.random.randint(((- 1) << 12), (1 << 12), ((1 << 15), 5))
i = numpy.random.choice(len(arr), (len(arr) * 4))
arr = numpy.vstack((arr, arr[i]))
tempResult = permutation(len(arr))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 613	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 642	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
tempResult = permutation(len(left))
	
===================================================================	
TestMergeMulti.test_int64_overflow_issues: 645	
----------------------------	

from itertools import product
from collections import defaultdict
from pandas.core.groupby import _int64_overflow_possible
df1 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G1']))
df2 = DataFrame(numpy.random.randn(1000, 7), columns=(list('ABCDEF') + ['G2']))
result = merge(df1, df2, how='outer')
self.assertTrue((len(result) == 2000))
(low, high, n) = (((- 1) << 10), (1 << 10), (1 << 20))
left = DataFrame(numpy.random.randint(low, high, (n, 7)), columns=list('ABCDEFG'))
left['left'] = left.sum(axis=1)
i = numpy.random.permutation(len(left))
right = left.iloc[i].copy()
right.columns = (right.columns[:(- 1)].tolist() + ['right'])
right.index = numpy.arange(len(right))
right['right'] *= (- 1)
out = merge(left, right, how='outer')
self.assertEqual(len(out), len(left))
assert_series_equal(out['left'], (- out['right']), check_names=False)
result = out.iloc[:, :(- 2)].sum(axis=1)
assert_series_equal(out['left'], result, check_names=False)
self.assertTrue((result.name is None))
out.sort_values(out.columns.tolist(), inplace=True)
out.index = numpy.arange(len(out))
for how in ['left', 'right', 'outer', 'inner']:
    assert_frame_equal(out, merge(left, right, how=how, sort=True))
out = merge(left, right, how='left', sort=False)
assert_frame_equal(left, out[left.columns.tolist()])
out = merge(right, left, how='left', sort=False)
assert_frame_equal(right, out[right.columns.tolist()])
n = (1 << 11)
left = DataFrame(np.random.randint(low, high, (n, 7)).astype('int64'), columns=list('ABCDEFG'))
shape = left.apply(Series.nunique).values
self.assertTrue(_int64_overflow_possible(shape))
left = concat([left, left], ignore_index=True)
right = DataFrame(np.random.randint(low, high, ((n // 2), 7)).astype('int64'), columns=list('ABCDEFG'))
i = numpy.random.choice(len(left), n)
right = concat([right, right, left.iloc[i]], ignore_index=True)
left['left'] = numpy.random.randn(len(left))
right['right'] = numpy.random.randn(len(right))
i = numpy.random.permutation(len(left))
left = left.iloc[i].copy()
left.index = numpy.arange(len(left))
tempResult = permutation(len(right))
	
===================================================================	
TestDatetimeIndex.test_resample_not_monotonic: 1075	
----------------------------	

rng = pandas.date_range('2012-06-12', periods=200, freq='h')
ts = Series(numpy.random.randn(len(rng)), index=rng)
tempResult = permutation(len(ts))
	
***************************************************	
dask_dask-0.7.0: 0	
***************************************************	
nengo_nengo-2.0.0: 0	
***************************************************	
sympy_sympy-1.0.0: 0	
***************************************************	
daducci_amico-dev: 0	
***************************************************	
aplpy_aplpy-1.1.1: 0	
***************************************************	
markovmodel_msmtools-1.0.2: 0	
***************************************************	
nilearn_nilearn-0.4.0: 1	
===================================================================	
test_searchlight: 56	
----------------------------	

rand = numpy.random.RandomState(0)
frames = 30
data = rand.rand(5, 5, 5, frames)
mask = numpy.ones((5, 5, 5), numpy.bool)
mask_img = nibabel.Nifti1Image(mask.astype(numpy.int), numpy.eye(4))
cond = (numpy.arange(frames, dtype=int) > (frames // 2))
data[2, 2, 2, :] = 0
data[(2, 2, 2)][cond.astype(numpy.bool)] = 2
data_img = nibabel.Nifti1Image(data, numpy.eye(4))
if (LooseVersion(sklearn.__version__) >= LooseVersion('0.18')):
    from sklearn.model_selection import KFold
    cv = KFold(n_splits=4)
else:
    from sklearn.cross_validation import KFold
    cv = KFold(len(cond), 4)
n_jobs = 1
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=mask_img, radius=0.5, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 1)
assert_equal(sl.scores_[(2, 2, 2)], 1.0)
process_mask = numpy.zeros((5, 5, 5), numpy.bool)
process_mask[(0, 0, 0)] = True
process_mask_img = nibabel.Nifti1Image(process_mask.astype(numpy.int), numpy.eye(4))
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=process_mask_img, radius=0.5, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 0)
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=mask_img, radius=1, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 7)
assert_equal(sl.scores_[(2, 2, 2)], 1.0)
assert_equal(sl.scores_[(1, 2, 2)], 1.0)
assert_equal(sl.scores_[(2, 1, 2)], 1.0)
assert_equal(sl.scores_[(2, 2, 1)], 1.0)
assert_equal(sl.scores_[(3, 2, 2)], 1.0)
assert_equal(sl.scores_[(2, 3, 2)], 1.0)
assert_equal(sl.scores_[(2, 2, 3)], 1.0)
sl = nilearn.decoding.searchlight.SearchLight(mask_img, process_mask_img=mask_img, radius=2, n_jobs=n_jobs, scoring='accuracy', cv=cv)
sl.fit(data_img, cond)
assert_equal(np.where((sl.scores_ == 1))[0].size, 33)
assert_equal(sl.scores_[(2, 2, 2)], 1.0)
try:
    from sklearn.model_selection import LeaveOneGroupOut
    gcv = LeaveOneGroupOut()
except ImportError:
    gcv = cv
tempResult = permutation((numpy.arange(frames, dtype=int) > (frames // 2)))
	
***************************************************	
poliastro_poliastro-0.8.0: 0	
***************************************************	
skimage_skimage-0.13.0: 0	
***************************************************	
sunpy_sunpy-0.8.0: 0	
***************************************************	
spacetelescope_synphot-0.1: 0	
***************************************************	
librosa_librosa-0.5.1: 0	
***************************************************	
mne_python-0.15.0: 0	
***************************************************	
